{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing  \n",
    "In this file I prepare the data for exploration by cleaning missing values, simplifying catagories, and dropping anything unecessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset includes essay columns which whill be excluded from this project since they are outside the scope of what my goals are for this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('okcupid_profiles.csv')   \n",
    "kc = ['age', 'status', 'sex', 'orientation', 'body_type', 'diet', 'drinks', 'drugs', 'education', 'ethnicity', \n",
    "      'height', 'income', 'job','last_online', 'location', 'offspring', 'pets', 'religion', 'sign','smokes', 'speaks'] \n",
    "data = data[kc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>orientation</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>...</th>\n",
       "      <th>income</th>\n",
       "      <th>job</th>\n",
       "      <th>last_online</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>asian, white</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>transportation</td>\n",
       "      <td>2012-06-28-20-30</td>\n",
       "      <td>south san francisco, california</td>\n",
       "      <td>doesn't have kids, but might want them</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism and very serious about it</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>80000</td>\n",
       "      <td>hospitality / travel</td>\n",
       "      <td>2012-06-29-21-41</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>doesn't have kids, but might want them</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly), french (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>available</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-06-27-09-10</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>has cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pisces but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english, french, c++</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     status sex orientation       body_type               diet  \\\n",
       "0   22     single   m    straight  a little extra  strictly anything   \n",
       "1   35     single   m    straight         average       mostly other   \n",
       "2   38  available   m    straight            thin           anything   \n",
       "\n",
       "     drinks      drugs                       education     ethnicity  ...  \\\n",
       "0  socially      never   working on college/university  asian, white  ...   \n",
       "1     often  sometimes           working on space camp         white  ...   \n",
       "2  socially        NaN  graduated from masters program           NaN  ...   \n",
       "\n",
       "   income                   job       last_online  \\\n",
       "0      -1        transportation  2012-06-28-20-30   \n",
       "1   80000  hospitality / travel  2012-06-29-21-41   \n",
       "2      -1                   NaN  2012-06-27-09-10   \n",
       "\n",
       "                          location                               offspring  \\\n",
       "0  south san francisco, california  doesn't have kids, but might want them   \n",
       "1              oakland, california  doesn't have kids, but might want them   \n",
       "2        san francisco, california                                     NaN   \n",
       "\n",
       "                        pets                                  religion  \\\n",
       "0  likes dogs and likes cats     agnosticism and very serious about it   \n",
       "1  likes dogs and likes cats  agnosticism but not too serious about it   \n",
       "2                   has cats                                       NaN   \n",
       "\n",
       "                                 sign     smokes  \\\n",
       "0                              gemini  sometimes   \n",
       "1                              cancer         no   \n",
       "2  pisces but it doesn&rsquo;t matter         no   \n",
       "\n",
       "                                              speaks  \n",
       "0                                            english  \n",
       "1  english (fluently), spanish (poorly), french (...  \n",
       "2                               english, french, c++  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with the Target Variable\n",
    "Here I begin to look at each individual column and start making decisions about what to keep or simplify. Starting with my target variable. Because the is going to be my target variable, I will start by removing the categories I will not be including using and creating a new column that aligns with my question by turning the job category into a binary. The column will answer whether or not the observation work in science/tech/computers or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we narrow down the observations to those tha can actually be identified are not ambiguos such as student, retired, etc.\n",
    "jobs_being_used = ['transportation', 'hospitality / travel', 'artistic / musical / writer', 'computer / hardware / software',\n",
    "       'banking / financial / real estate', 'entertainment / media','sales / marketing / biz dev','medicine / health',\n",
    "       'science / tech / engineering', 'executive / management','education / academia', 'clerical / administrative',\n",
    "       'construction / craftsmanship', 'political / government', 'law / legal services','military'] \n",
    "df = data[data['job'].isin(jobs_being_used)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "science / tech / engineering         4848\n",
       "computer / hardware / software       4709\n",
       "artistic / musical / writer          4439\n",
       "sales / marketing / biz dev          4391\n",
       "medicine / health                    3680\n",
       "education / academia                 3513\n",
       "executive / management               2373\n",
       "banking / financial / real estate    2266\n",
       "entertainment / media                2250\n",
       "law / legal services                 1381\n",
       "hospitality / travel                 1364\n",
       "construction / craftsmanship         1021\n",
       "clerical / administrative             805\n",
       "political / government                708\n",
       "transportation                        366\n",
       "military                              204\n",
       "Name: job, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.job.value_counts() #Checks the value counts for each of the job catagories   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating another column that identies whether an observation belongs to my target class or not\n",
    "df['works_in_tech'] = np.nan \n",
    "df.job.replace(['computer / hardware / software','science / tech / engineering'\n",
    "                     ],'science/tech/computers', inplace=True)  \n",
    "def tech_column(row): \n",
    "    if row['job'] ==  'science/tech/computers': \n",
    "        row['works_in_tech'] = 1 \n",
    "    else: \n",
    "        row['works_in_tech'] = 0  \n",
    "    return row \n",
    "\n",
    "df = df.apply(tech_column, axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    28761\n",
       "1     9557\n",
       "Name: works_in_tech, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['works_in_tech'].value_counts() #checks to values counts for my newly created column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tranforming the Features\n",
    "Having dealt with the target, I can move on to tranforming every other column, deciding whether or not to use it, and dealing with missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                     0\n",
       "sex                     0\n",
       "orientation             0\n",
       "body_type               0\n",
       "diet                    0\n",
       "drinks                  0\n",
       "drugs                   0\n",
       "education               0\n",
       "ethnicity               0\n",
       "height                  0\n",
       "job                     0\n",
       "location                0\n",
       "offspring               0\n",
       "pets                    0\n",
       "religion                0\n",
       "sign                    0\n",
       "smokes                  0\n",
       "speaks                  0\n",
       "works_in_tech           0\n",
       "above_average_height    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age Column \n",
    "The age column contains no missing values and has multiple values in each age and so will be left as is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    38318.000000\n",
       "mean        33.368313\n",
       "std          9.250639\n",
       "min         18.000000\n",
       "25%         27.000000\n",
       "50%         31.000000\n",
       "75%         38.000000\n",
       "max         69.000000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.age.describe() #Summerizes the age column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Status Column \n",
    "Because this data is coming from a dating site this is unlikely to representative and so will be dropped.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sex Column \n",
    "This columns contains no missing values, but will be renames for clarity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      24042\n",
       "female    14276\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sex'] = df['sex'].replace(['m','f'],['male','female']) \n",
    "df.sex.value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orientation Column \n",
    "This column is highly imbalanaced but will be left as is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "straight    33558\n",
       "gay          3325\n",
       "bisexual     1435\n",
       "Name: orientation, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.orientation.value_counts() #Returns the catagory "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Body Type Column \n",
    "This column has been reconfigured to group up similar descriptions. I have also changed the descriptions of \"jacked\" and \"used up\" as they are descriptors with ambiguous meaning and changed nan and 'rather not say' to unknown. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body_fit/athletic          16835\n",
       "body_average                9784\n",
       "body_curvy/full_figured     4882\n",
       "body_thin/skinny            3924\n",
       "unknown_body_type           2893\n",
       "Name: body_type, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['body_type'] = df['body_type'].replace(['fit','athletic','thin','skinny','curvy','a little extra', 'full figured', 'overweight',\n",
    "                                          'jacked','used up', 'rather not say','average'],\n",
    "                                          ['body_fit/athletic','body_fit/athletic','body_thin/skinny','body_thin/skinny', \n",
    "                                           'body_curvy/full_figured', 'body_curvy/full_figured','body_curvy/full_figured',\n",
    "                                           'body_curvy/full_figured', 'body_average', 'body_average', 'body_average','body_average'])#This code regroups and renames observations\n",
    "df['body_type'] = df['body_type'].fillna('unknown_body_type') #This gives a value to missing values\n",
    "df.body_type.value_counts() #Checks the counts of this column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diet Column \n",
    "#This column had a large number of missing values. I chose to include them in the anything catagory for the sake retaining as much \n",
    "#data as possible but also with the assumption that if wasn't important enough to fill in it is unlikely to be too relevant to the \n",
    "#observations life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diet_anything            18751\n",
       "unkown_diet              14760\n",
       "diet_vegan/vegetarian     3563\n",
       "diet_other                1244\n",
       "Name: diet, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diet'] = df['diet'].replace(['strictly anything', 'mostly other', 'mostly anything', 'mostly vegetarian', 'strictly vegan', \n",
    "                                  'vegetarian','mostly halal', 'strictly vegetarian', 'strictly other', 'mostly kosher',\n",
    "                                 'mostly vegan', 'vegan', 'strictly kosher', 'kosher', 'strictly halal', 'halal','other','anything'],\n",
    "                                          ['diet_anything','diet_other','diet_anything','diet_vegan/vegetarian', 'diet_vegan/vegetarian', 'diet_vegan/vegetarian',\n",
    "                                          'diet_other','diet_vegan/vegetarian', 'diet_other', 'diet_other', 'diet_vegan/vegetarian', 'diet_vegan/vegetarian','diet_other',\n",
    "                                          'diet_other','diet_other','diet_other','diet_other','diet_anything'])#This code regroups and renames observations\n",
    "df['diet'] = df['diet'].fillna('unkown_diet') #This gives a value to missing values\n",
    "df.diet.value_counts() #Checks the counts of this column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drinks Column \n",
    "This will be simplified through regrouping and have missing values filled in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drinks                      31560\n",
       "drinks_rarely/not_at_all     5566\n",
       "unknown_if_drinker           1192\n",
       "Name: drinks, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['drinks'] = df['drinks'].replace(['socially', 'often', 'not at all', 'rarely','very often','desperately'], #renames and regroups column\n",
    "                                    ['drinks', 'drinks','drinks_rarely/not_at_all','drinks_rarely/not_at_all','drinks','drinks' ])\n",
    "df['drinks'] = df['drinks'].fillna('unknown_if_drinker') #fills in missing values\n",
    "df.drinks.value_counts() #checks value counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drugs Column \n",
    "This will be simplified through regrouping and have missing values filled in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no_drugs            24457\n",
       "unknown_if_drugs     8987\n",
       "drugs                4874\n",
       "Name: drugs, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['drugs'] = df['drugs'].replace(['never', 'sometimes', 'often'],\n",
    "                                ['no_drugs', 'drugs','drugs'])#renames and regroups column\n",
    "df['drugs'] = df['drugs'].fillna('unknown_if_drugs') #fills in missing values\n",
    "df.drugs.value_counts() #checks value counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Education Column \n",
    "This will be simplified through regrouping and have missing values filled in as well as changing any \"space camp\" responses to unknown since it seems unlikely that many people went to space camp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "college_graduate_or_higher    30337\n",
       "no_college_degree              4302\n",
       "unknown_education              3679\n",
       "Name: education, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.education.replace(['graduated from college/university','working on masters program','graduated from masters program', \n",
    "                      'college/university','graduated from law school', 'graduated from two-year college','working on med school',\n",
    "                       'graduated from ph.d program','graduated from med school', 'two-year college', 'working on ph.d program',\n",
    "                       'dropped out of ph.d program','dropped out of med school','working on law school',\n",
    "                      'dropped out of masters program', 'masters program', 'ph.d program', 'law school',\n",
    "                      'dropped out of law school', 'med school'], 'college_graduate_or_higher', inplace=True) #renames and regroups column\n",
    "\n",
    "df.education.replace(['working on college/university','dropped out of college/university','dropped out of high school',\n",
    "                      'dropped out of two-year college', 'working on two-year college','high school', 'graduated from high school',\n",
    "                      'working on high school'],'no_college_degree', inplace=True)  #renames and regroups column\n",
    "\n",
    "df.education.replace(['working on space camp', 'graduated from space camp', 'dropped out of space camp',\n",
    "                     'dropped out of space camp','space camp'\n",
    "                     ],'unknown_education', inplace=True)   #renames and regroups column\n",
    "df['education'] = df['education'].fillna('unknown_education') #fills in missing values\n",
    "df.education.value_counts() #checks value counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethnicity Column \n",
    "This column included multiple versions of mixed ethnicity so in an attempt somewhat even out the the minority groups I regrouped them by ones containing the names of some of the majority groups. The rest will be grouped as other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "white                      22056\n",
       "ethnicity_other/unknown     5112\n",
       "asian                       4971\n",
       "hispanic/latin              2833\n",
       "black                       1797\n",
       "indian                      1055\n",
       "middle_eastern               494\n",
       "Name: ethnicity, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ethnicity'] = df['ethnicity'].fillna('ethnicity_other/unknown') #fills in missing values\n",
    "df.loc[df['ethnicity'].str.contains('indian'), 'ethnicity'] = 'indian' #renames and regroups all containing this ethnicity\n",
    "df.loc[df['ethnicity'].str.contains('middle eastern'), 'ethnicity'] = 'middle_eastern' #renames and regroups all containing this ethnicity\n",
    "df.loc[df['ethnicity'].str.contains('black'), 'ethnicity'] = 'black' #renames and regroups all containing this ethnicity\n",
    "df.loc[df['ethnicity'].str.contains('hispanic'), 'ethnicity'] = 'hispanic/latin' #renames and regroups all containing this ethnicity\n",
    "df.loc[df['ethnicity'].str.contains('asian'), 'ethnicity'] = 'asian' #renames and regroups all containing this ethnicity\n",
    "df.ethnicity.replace(['pacific islander, white','pacific islander', 'native american, white', 'native american, white, other', \n",
    "                      'white, other','other', 'native american', 'pacific islander, other', 'pacific islander, white, other',\n",
    "                      'native american, other', 'native american, pacific islander, white', \n",
    "                      'native american, pacific islander, white, other', 'native american, pacific islander'],'ethnicity_other/unknown', inplace=True) #renames and regroups all containing this ethnicity \n",
    "df.ethnicity.value_counts() #checks value counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Height Column \n",
    "The column will be capped to reasonable nubers as descibed by this website: https://dqydj.com/height-percentile-calculator-for-men-and-women/.\n",
    "According to this less than 1 percent of women are below 4'8\" and less than 1 percent of men are taller than 6'3\" with an std of about three inches inbetween. I will also create a new column that answers whether the observation is above average height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap_height(row): #Is function that caps the height column\n",
    "    if row['height'] > 75.0:\n",
    "        row['height'] = 79.0 #column average\n",
    "    if row['height'] < 52:\n",
    "        row['height'] = 56\n",
    "    return row  \n",
    "df = df.apply(cap_height, axis = 1)        #applies the above function to the height column \n",
    "df = df[df['height'].notna()]   #drops the 1 missing value column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    38317.000000\n",
       "mean        68.531931\n",
       "std          3.948027\n",
       "min         52.000000\n",
       "25%         66.000000\n",
       "50%         69.000000\n",
       "75%         71.000000\n",
       "max         79.000000\n",
       "Name: height, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.height.describe() #checks value counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    " df['above_average_height'] = np.nan #Creates an empty function\n",
    "def aah_column(row): #Creates a function that populates the height column\n",
    "    male_avg = 69.2\n",
    "    female_avg = 63.6\n",
    "    if row['sex'] == 'm':\n",
    "        if row['height'] > male_avg: \n",
    "            row['above_average_height'] = 'above_average_height' \n",
    "        else: \n",
    "            row['above_average_height'] = 'not_above_average_height' \n",
    "    else: \n",
    "        if row['height'] > female_avg: \n",
    "            row['above_average_height'] = 'above_average_height'  \n",
    "        else: \n",
    "            row['above_average_height'] = 'not_above_average_height'\n",
    "    return row \n",
    "\n",
    "df = df.apply(aah_column, axis = 1)#applies the above function to the height column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "above_average_height        34106\n",
       "not_above_average_height     4211\n",
       "Name: above_average_height, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.above_average_height.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Income Column \n",
    "#Column will be dropped due to most not having answered this question and being that it is from a dating site, the chances of users inflating this number in my opinion is high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['income'] #drops the income column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last Online Column \n",
    "#I dont think column serves any purpose for my model especially given the limited time frame of the data collectionso it will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['last_online'] #drops the last online column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location Column \n",
    "#The data for this data set was collected in the city of sanfrancisco so most observations are in that city. For the sake of simplicity I will be turning this column into a binary depending on simply whether or not the observation is in sanfrancisco. Additionally, I wonder if the column will even be worht keeping given that \"not san fran\" can include so many other places. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "san_francisco_ca     21067\n",
       "not_san_francisco    17250\n",
       "Name: location, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['location'] = df['location'].fillna('not_san_francisco') #fills missing values\n",
    "df.location.replace(['san francisco, california', 'south san francisco, california'],  'san_francisco_ca', inplace=True) \n",
    "#df['location'] = np.where(df['location'] in ['san francisco, california', 'south san francisco, california'], 'san_francisco_ca', 'not_san_francisco')\n",
    "df.location.replace(['oakland, california', 'daly city, california','atherton, california', \n",
    "                     'san leandro, california', 'san rafael, california', 'walnut creek, california',  'berkeley, california', \n",
    "                     'belmont, california','san jose, california', 'palo alto, california', 'emeryville, california', \n",
    "                     'el granada, california', 'castro valley, california', 'fairfax, california','mountain view, california', \n",
    "                     'menlo park, california', 'burlingame, california', 'alameda, california','benicia, california', \n",
    "                     'mill valley, california', 'san mateo, california', 'redwood city, california', 'el cerrito, california', \n",
    "                     'stanford, california', 'san pablo, california', 'lafayette, california', 'fremont, california', \n",
    "                     'orinda, california', 'novato, california', 'vallejo, california', 'san lorenzo, california','san carlos, california', 'pacifica, california',\n",
    "                     'hayward, california', 'foster city, california','hercules, california', 'bolinas, california',\n",
    "                     'larkspur, california', 'moraga, california', 'albany, california','martinez, california', 'san bruno, california',\n",
    "                     'millbrae, california', 'el sobrante, california','richmond, california', 'petaluma, california','pinole, california', 'pleasant hill, california',\n",
    "                     'san geronimo, california', 'san anselmo, california','sausalito, california', 'crockett, california',\n",
    "                    'boulder, colorado', 'half moon bay, california','belvedere tiburon, california', 'montara, california', 'corte madera, california', 'new york, new york',\n",
    "                     'green brae, california', 'ross, california', 'east palo alto, california', 'brisbane, california',\n",
    "                     'hacienda heights, california', 'point richmond, california','sacramento, california', 'rodeo, california', 'portland, oregon',\n",
    "                       'tucson, arizona', 'honolulu, hawaii', 'billings, montana','west oakland, california', 'glencove, california',\n",
    "                       'tiburon, california', 'peoria, illinois', 'bellwood, illinois',\n",
    "                       'nha trang, vietnam', 'hillsborough, california','moss beach, california', 'kensington, california', 'kentfield, california', 'redwood shores, california',\n",
    "                       'woodside, california', 'lagunitas, california','studio city, california', 'concord, california','forest knolls, california', 'edinburgh, united kingdom',\n",
    "                       'london, united kingdom', 'chicago, illinois', 'colma, california','los angeles, california', 'south wellfleet, massachusetts', 'piedmont, california', 'los gatos, california', 'boise, idaho',\n",
    "                       'islip terrace, new york', 'sunnyvale, california', 'cambridge, massachusetts', 'ozone park, new york','jackson, mississippi', 'south orange, new jersey','atlanta, georgia', 'madrid, spain', 'port costa, california','nicasio, california', 'bellingham, washington',\n",
    "                       'woodacre, california', 'boston, massachusetts','longwood, florida', 'westlake, california','granite bay, california', 'campbell, california',\n",
    "                       'santa ana, california', 'santa rosa, california', 'nevada city, california', 'providence, rhode island','stockton, california', 'vancouver, british columbia, canada','pacheco, california', 'irvine, california',\n",
    "                       'kansas city, missouri', 'kassel, germany','stinson beach, california', 'philadelphia, pennsylvania', 'amsterdam, netherlands', 'napa, california', 'austin, texas','brooklyn, new york', 'bonaduz, switzerland',\n",
    "                       'salt lake city, utah', 'bayshore, california', 'south lake tahoe, california', 'vacaville, california', 'miami, florida', 'long beach, california', 'cincinnati, ohio','phoenix, arizona', 'rochester, michigan', 'santa cruz, california',\n",
    "                        'freedom, california', 'san quentin, california','utica, michigan', 'seaside, california', 'santa monica, california', 'woodbridge, virginia',\n",
    "                        'arcadia, california', 'san antonio, texas', 'kula, hawaii','washington, district of columbia', 'muir beach, california','canyon, california', 'minneapolis, minnesota','san diego, california'], \n",
    "                    'not_san_francisco', inplace=True)  #renames and regroups column \n",
    "df.location.value_counts() #checks value counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offspring Column \n",
    "#This column has many missing values, approximately 60% which will likely end up being the largest group here. For the rest they will simplified to whether or not they have kids. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown_if_kids    21721\n",
       "no_kids            13069\n",
       "has_kids            3527\n",
       "Name: offspring, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['offspring'] = df['offspring'].fillna('unknown_if_kids') #fills missing values\n",
    "df.offspring.replace(['has a kid', 'has kids', \"has kids, but doesn't want more\", \"has a kid, but doesn't want more\",\n",
    "                      'has kids, and might want more', 'has a kid, and might want more', 'has a kid, and wants more', \n",
    "                      'has kids, and wants more'\n",
    "                     ],'has_kids', inplace=True) #renames and regroups column \n",
    "df.offspring.replace([\"doesn't have kids, but might want them\",\"doesn't have kids, but wants them\", \"doesn't have kids\",\n",
    "                      'might want kids', \"doesn't have kids, and doesn't want any\", \"doesn't want kids\",'wants kids',\n",
    "                     ],'no_kids', inplace=True) #renames and regroups column \n",
    "df.offspring.value_counts() #checks value counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pets Column \n",
    "This column contained many attitudes but it has been simplified to just wether observations like both cats and dogs, likes cats or dogs, and like neither. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "likes_dogs_and_cats          15161\n",
       "unknown_pet_feelings         11502\n",
       "likes_dogs                    9538\n",
       "likes_cats                    1875\n",
       "dislikes_cats_and_or_dogs      241\n",
       "Name: pets, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pets'] = df['pets'].fillna('unknown_pet_feelings') #fills missing values\n",
    "df.pets.replace(['likes dogs and likes cats', 'likes dogs and has cats','has dogs and likes cats','has dogs and has cats', \n",
    "                     ],'likes_dogs_and_cats', inplace=True) #renames and regroups column\n",
    "df.pets.replace(['likes dogs and dislikes cats','has dogs','likes dogs','has dogs and dislikes cats',\n",
    "                     ],'likes_dogs', inplace=True) #renames and regroups column\n",
    "df.pets.replace(['likes cats','has cats','dislikes dogs and likes cats', 'dislikes dogs and has cats'\n",
    "                     ],'likes_cats', inplace=True) #renames and regroups column\n",
    "df.pets.replace(['dislikes cats','dislikes dogs and dislikes cats','dislikes dogs'\n",
    "                     ],'dislikes_cats_and_or_dogs', inplace=True) #renames and regroups column\n",
    "df.pets.value_counts() #checks value counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Religion Column \n",
    "This column has been simplified to remove attitudes about religion as well as fill in missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "religion_other/unknown    16602\n",
       "agnosticism                6084\n",
       "atheism                    4659\n",
       "christianity               3788\n",
       "catholicism                3265\n",
       "judaism                    2165\n",
       "buddhism                   1340\n",
       "hinduism                    341\n",
       "islam                        73\n",
       "Name: religion, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['religion'] = df['religion'].fillna('religion_other/unknown') #fills missing values\n",
    "df.loc[df['religion'].str.contains('agnosticism'), 'religion'] = 'agnosticism' #renames and regroups column\n",
    "df.loc[df['religion'].str.contains('catholicism'), 'religion'] = 'catholicism' #renames and regroups column\n",
    "df.loc[df['religion'].str.contains('christianity'), 'religion'] = 'christianity' #renames and regroups column\n",
    "df.loc[df['religion'].str.contains('atheism'), 'religion'] = 'atheism' #renames and regroups column\n",
    "df.loc[df['religion'].str.contains('judaism'), 'religion'] = 'judaism' #renames and regroups column\n",
    "df.loc[df['religion'].str.contains('buddhism'), 'religion'] = 'buddhism' #renames and regroups column\n",
    "df.loc[df['religion'].str.contains('hinduism'), 'religion'] = 'hinduism' #renames and regroups column\n",
    "df.loc[df['religion'].str.contains('other'), 'religion'] = 'religion_other/unknown' #renames and regroups column\n",
    "df.loc[df['religion'].str.contains('islam'), 'religion'] = 'islam'  #renames and regroups column\n",
    "df.religion.value_counts() #checks value counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sign Column \n",
    "This column has been simplified to remove attitudes about astrology as well as fill in missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sign_unknown    6173\n",
       "gemini          2884\n",
       "leo             2879\n",
       "cancer          2796\n",
       "libra           2772\n",
       "scorpio         2762\n",
       "taurus          2713\n",
       "virgo           2696\n",
       "aries           2608\n",
       "pisces          2600\n",
       "aquarius        2562\n",
       "sagittarius     2534\n",
       "capricorn       2338\n",
       "Name: sign, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sign'] = df['sign'].fillna('sign_unknown') #fills missing values\n",
    "df.loc[df['sign'].str.contains('aries'), 'sign'] = 'aries' #renames and regroups column\n",
    "df.loc[df['sign'].str.contains('taurus'), 'sign'] = 'taurus' #renames and regroups column\n",
    "df.loc[df['sign'].str.contains('gemini'), 'sign'] = 'gemini' #renames and regroups column\n",
    "df.loc[df['sign'].str.contains('cancer'), 'sign'] = 'cancer' #renames and regroups column\n",
    "df.loc[df['sign'].str.contains('leo'), 'sign'] = 'leo' #renames and regroups column\n",
    "df.loc[df['sign'].str.contains('virgo'), 'sign'] = 'virgo' #renames and regroups column\n",
    "df.loc[df['sign'].str.contains('libra'), 'sign'] = 'libra' #renames and regroups column\n",
    "df.loc[df['sign'].str.contains('scorpio'), 'sign'] = 'scorpio' #renames and regroups column\n",
    "df.loc[df['sign'].str.contains('sagittarius'), 'sign'] = 'sagittarius' #renames and regroups column\n",
    "df.loc[df['sign'].str.contains('capricorn'), 'sign'] = 'capricorn' #renames and regroups column\n",
    "df.loc[df['sign'].str.contains('aquarius'), 'sign'] = 'aquarius' #renames and regroups column\n",
    "df.loc[df['sign'].str.contains('pisces'), 'sign'] = 'pisces' #renames and regroups column\n",
    "df.sign.value_counts() #checks value counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smokes Column \n",
    "This column has been simplified to remove the amount they smoke as well as fill in missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "does_not_smoke       29396\n",
       "smokes                6150\n",
       "unknown_if_smokes     2771\n",
       "Name: smokes, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['smokes'] = df['smokes'].fillna('unknown_if_smokes') #fills missing values\n",
    "df.smokes.replace(['no'],'does_not_smoke', inplace=True) #renames and regroups column\n",
    "df.smokes.replace(['sometimes','when drinking','yes','trying to quit'],'smokes', inplace=True) #renames and regroups column\n",
    "df.smokes.value_counts() #checks value counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speaks Column \n",
    "#This column will be adjusted since it includes english plus other languages. Since all but 30 observations are known and include english I decided to note if the observation speaks one of the other top 8 languages (not included english) of starting with the least popular and moving up thru most popular. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speaks_english       23742\n",
       "speaks_spanish        9334\n",
       "speaks_chinese        1612\n",
       "speaks_japanese       1506\n",
       "speaks_russian         844\n",
       "speaks_portuguese      659\n",
       "speaks_hindi           536\n",
       "speaks_bengali          54\n",
       "language_unknown        30\n",
       "Name: speaks, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['speaks'] = df['speaks'].fillna('language_unknown') #fills missing values\n",
    "df.loc[df['speaks'].str.contains('japanese'), 'speaks'] = 'speaks_japanese' #renames and regroups column\n",
    "df.loc[df['speaks'].str.contains('russian'), 'speaks'] = 'speaks_russian' #renames and regroups column\n",
    "df.loc[df['speaks'].str.contains('portuguese'), 'speaks'] = 'speaks_portuguese' #renames and regroups column\n",
    "df.loc[df['speaks'].str.contains('bengali'), 'speaks'] = 'speaks_bengali' #renames and regroups column\n",
    "df.loc[df['speaks'].str.contains('hindi'), 'speaks'] = 'speaks_hindi' #renames and regroups column\n",
    "df.loc[df['speaks'].str.contains('spanish'), 'speaks'] = 'speaks_spanish' #renames and regroups column\n",
    "df.loc[df['speaks'].str.contains('chinese'), 'speaks'] = 'speaks_chinese' #renames and regroups column\n",
    "df.loc[df['speaks'].str.contains('english'), 'speaks'] = 'speaks_english' #renames and regroups column\n",
    "df.speaks.value_counts() #checks value counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Cleaned Data Set\n",
    "#Having addressed in all the features, I will now save all of these changes as a new csv file to begin data exploration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('processed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
